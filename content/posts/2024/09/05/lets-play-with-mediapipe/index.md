---
title: "Let's play with MediaPipe"
date: "2024-09-05"
featured_image:
  caption: "MediaPipe logo"
  image: mediapipe.png
tags:
  - adonisjs
  - mediapipe
  - preact
  - web-components
toc: true
draft: true
---

Cet avril dernier, quelque temps apr√®s la sortie officielle de la mise √† jours de [AdonisJS 6](https://adonisjs.com/), j'ai eu l'occasion de travailler sur un projet personnel qui m'a permis de d√©couvrir et d'exp√©rimenter avec [MediaPipe](https://mediapipe.dev/), une biblioth√®que open-source de Google pour le traitement de flux multim√©dia.

<!--more-->

## Introduction

Dans le cadre de mon alternance, j'ai pu d√©couvrir par le biais de mon tuteur un projet de recherche de Google nomm√© [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/guide). Une biblioth√®que open-source qui permet de traiter des flux multim√©dia en temps r√©el. Cela va de la d√©tection d'objets, de visages, de mains, de pose, de mouvements, etc.

Mon tuteur s'en servait pour proposer du _background replacement_ lors de ses visioconf√©rences. C'est-√†-dire, remplacer l'arri√®re-plan d'une vid√©o par une image ou une vid√©o de son choix. Permettant ainsi de cacher son environnement de travail.

Par curiosit√©, je me suis donc lanc√© dans un mini-projet pour d√©couvrir et exp√©rimenter avec cette biblioth√®que.

## Le choix de la stack

√âtant donn√© l'aspect d√©couverte du projet, je suis parti sur quelque chose de totalement nouveau pour moi.
Tout d'abord, m√™me si cela n'est pas n√©cessaire, j'ai lanc√© un projet [AdonisJS 6](https://adonisjs.com/) pour le backend. Bien entendu, je ne me suis pas juste content√© de lancer un projet avec les outils par d√©faut. J'ai √©galement remplac√© le moteur de rendu [Edge](https://edgejs.dev/) qui est par d√©faut dans Adonis, par [`@kitajs/html`](https://github.com/kitajs/html), un moteur me permettant de transformer des composants JSX en page HTML. La mise en place fut l√©g√®rement compliqu√©e, mais une fois configur√©, la prise en main √©tait tr√®s simple et agr√©able √† utiliser.

C'est maintenant ici que la partie la plus int√©ressante arrive : le code frontend qui s'occupera de g√©rer Mediapipe. Pour cela, je suis rest√© sur un visuel succinct avec [Tailwind](https://tailwindcss.com). Par contre, pour afficher mon interface avec Mediapipe, je me suis pens√© sur les [Web Components](https://developer.mozilla.org/fr/docs/Web/Web_Components) avec l'utilisation de [Preact](https://preactjs.com/) pour la partie JavaScript.

Forc√©ment, je suis conscient que cette stack n'a strictement aucun sens pour un projet de production. Mais pour un projet personnel, cela m'a permis de d√©couvrir de nouvelles technologies et de m'amuser √† les utiliser. üôÉ

## La mise en place

### Kitajs

Comme dit pr√©c√©demment, j'ai utilis√© [`@kitajs/html`](https://github.com/kitajs/html) pour g√©rer mes pages HTML. Pour cela, j'ai suivi les explication fournit dans [ce post de blog](https://adonisjs.com/blog/use-tsx-for-your-template-engine).

Tout d'abord, j'ai install√© le package :

```bash
pnpm install @kitajs/html -D
pnpm install @kitajs/ts-html-plugin -D
```

Ensuite, j'ai configur√© mon fichier `tsconfig.json` pour ajouter le plugin typescript :

```json
// tsconfig.json
{
  // ...
  "compilerOptions": {
    // ...
    // on configure le moteur JSX pour typescript
    "jsx": "react",
    "jsxFactory": "Html.createElement",
    "jsxFragmentFactory": "Html.Fragment",
    "plugins": [{ "name": "@kitajs/ts-html-plugin" }]
  },
  "exclude": ["resources"]
}
```

Ce plugin va permet de faire comprendre √† Typescript comme interpr√©ter les √©l√©ments JSX.

Et pour finir, dans un contr√¥leur `app/app_controller.ts` et ma vue, j'ai pu utiliser le moteur de rendu :

```ts
// app/app_controller.ts
import { Home } from '../../resources/views/pages/home.js'

export default class AppsController {
  index() {
    return <Home />
  }
}
```

```tsx
// resources/views/pages/home.tsx

import { App } from "../layouts/app.js";

export function Home() {
  return (
    <App>
      <div class="relative">
        <div class="container mx-auto p-8 z-10 absolute top-0 left-0 w-full">
          <h1 class="font-bold text-2xl">Move your hands</h1>
        </div>

        <div class="w-screen h-screen">
          <video-container />
        </div>
      </div>
    </App>
  );
}
```

### Web Components

Vous avez d√ª remarqu√© dans la partie pr√©c√©dente que j'ai utilis√© une balise `video-container`. Cette balise est un Web Component que j'ai cr√©√© pour g√©rer l'affichage de la vid√©o et l'initialisation de Mediapipe.

La configuration d'un Web Component est assez simple, en particulier avec Preact. Il suffit de cr√©er un composant Preact et de l'enregistrer en tant que Web Component. Voici un exemple de composant :

```tsx
// resources/components/my-component.tsx
import { JSX } from "preact";
import register from "preact-custom-element";

function MyComponent(): JSX.Element {
  return <div>Hello World</div>;
}

register(MyComponent, "video-container");
```

Bien entendu, pour permettre √† typescript et kita de comprendre que notre composant existe et est valide, il nous faut ajouter des informations dans un fichier de d√©claration :

```ts
// types/kita.ts
declare global {
  namespace JSX {
    interface IntrinsicElements {
      ["video-container"]: HtmlTag;
    }
  }
}
```

Et c'est tout ! Notre composant est maintenant utilisable dans notre page HTML. (Attention, il faut bien s√ªr penser √† importer le script de notre composant dans notre page HTML et le d√©clarer dans la configuration Vite).

### Mediapipe

Je ne pense pas m'√©tendre sur utilisation de MediaPipe dans mon code, mais j'aimerais quand m√™me aborder certains points. Par exemple, la mani√®re dont j'ai g√©r√© l'initialisation de Mediapipe.

Tout d'abord, j'ai cr√©√© un fichier utilitaire pour g√©rer l'initialisation de Mediapipe :

```ts
// resources/ts/utils/vision.ts
import { FilesetResolver, GestureRecognizer } from "@mediapipe/tasks-vision";

export async function gestureRecogniser() {
  // On r√©cup√®re le module de vision
  const vision = await FilesetResolver.forVisionTasks(
    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm",
  );

  // On cr√©e le GestureRecognizer
  return await GestureRecognizer.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath:
        "https://storage.googleapis.com/mediapipe-tasks/gesture_recognizer/gesture_recognizer.task",
      delegate: "GPU",
    },
    runningMode: "VIDEO",
    numHands: 2,
  });
}
```

Ensuite, j'ai utilis√© ce fichier dans mon composant Web Component pour initialiser Mediapipe :

```tsx
function VideoContainer(): JSX.Element {
  const [visionRecogniser, setVision] = useState<GestureRecognizer>();
  const [visionData, setVisionData] = useState<GestureRecognizerResult | null>(
    null,
  );

  useEffect(() => {
    // On charge le vision recogniser
    const fetchVision = async () => {
      console.log("Loading vision recogniser");
      const { gestureRecogniser } = await import("../utils/vision");
      setVision(await gestureRecogniser());
    };

    fetchVision();
  }, []);

  let text: string | null = null;

  // On extrait les informations de Mediapipe pour les afficher
  if (visionData && visionData.gestures.length > 0) {
    const categoryName = visionData.gestures[0][0].categoryName;
    const categoryScore = (visionData.gestures[0][0].score * 100).toFixed(2);
    const handedness = visionData.handedness[0][0].displayName;

    text = `${categoryName} (${categoryScore}%) - ${handedness}`;
  }

  if (!visionRecogniser) {
    return <p>Loading...</p>;
  }

  // On retourne le composant
  return (
    <div class="relative mx-auto p-4">
      <WebcamProvider>
        <div class="relative w-fit mx-auto">
          <Video vision={visionRecogniser} onVisionData={setVisionData} />
          <Canvas data={visionData} />
        </div>
      </WebcamProvider>

      {visionData && <p class="absolute z-10 bottom-4">{text}</p>}
    </div>
  );
}
```

Et voil√†, notre composant est maintenant capable de g√©rer Mediapipe.
Le composant `<Video/>` s'occupe de r√©cup√©rer le flux vid√©o de la webcam et de le traiter avec Mediapipe. Le composant `<Canvas/>` s'occupe de dessiner les informations r√©cup√©r√©es par Mediapipe sur le flux vid√©o. Et le composant `<WebcamProvider/>` s'occupe de g√©rer l'acc√®s √† la webcam.

√Ä partir de l√†, il ne reste plus qu'√† ajouter les styles et les scripts n√©cessaires pour que notre composant fonctionne correctement.

## Conclusion

Ce projet fut tr√®s int√©ressant sur de nombreux point.

Tout d'abord, je me suis rendu compte que l'utilisation de JSX avec Kita comme moteur de rendu √©tait vraiment s√©duisant en comparaison √† ce qui existe d√©j√† avec EdgeJS. La capacit√© √† proposer des composants facilement r√©utilisables et _typescript-friendly_ est vraiment un plus !

Ensuite, j'ai pu d√©couvrir les Web Components et leur utilisation avec Preact. M√™me si je n'ai pas pu exploiter pleinement leur potentiel, j'ai pu voir √† quel point ils √©taient simples √† mettre en place et √† utiliser. Cela m'a permit de me rendre compte que l'utilisation de gros framework en Single-Page-App (tel que React, Vue ou Angular) n'√©tait pas une n√©cessit√© pour avoir de l'interactivit√© sur un site web. Les Web Components peuvent tr√®s bien faire le travail s'il est bien utilis√©.

Et pour finir, j'ai vraiment √©t√© surpris par la simplicit√© d'utilisation de la librairie MediaPipe, et la facilit√© pour mettre cette derni√®re en place dans un projet. M√™me si je n'ai pas pu exploiter pleinement les capacit√©s de cette librairie, j'ai pu voir son potentiel.

Je vous invite √† aller voir le code de ce projet sur mon [Github](https://github.com/Bricklou/media-pipe-demo/) pour voir comment j'ai mis en place tout cela.
