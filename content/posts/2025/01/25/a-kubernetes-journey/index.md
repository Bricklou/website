---
title: "A Kubernetes Journey"
date: "2025-01-24"
featured_image:
  caption: "Kubernetes logo"
  image: "kubernetes.png"
tags:
  - kubernetes
  - devops
  - continue-deployment
  - ci-cd
toc: true
---

Bonne annÃ©e Ã  tous ! ğŸ‰

Pour ce premier article de 2025, nous allons parler DevOps, ou plus particuliÃ¨rement Kubernetes. Cela sera l'occasion d'aborder des notions d'infrastructures,
de dÃ©ploiements continue, de gestion de secrets, etc.

<!--more-->

> [!WARNING]
>
> Avant d'aller plus loin, il est important de noter que je ne suis absolument pas un expert et il est fort probable que certaines de mes maniÃ¨res de faire ne
> soient abssoluments pas optimales ou recommendÃ©s. N'hÃ©sitez pas Ã  me faire part de vos retours pour m'aider Ã  m'amÃ©liorer.

## Introduction

Cela fait maintenant plusieurs annÃ©es que je possÃ¨de un home-server et il n'a cessÃ© d'Ã©voluer sur le plan technique ou sur celui de la puissance de calcul. Au
dÃ©but, il y a environs 9 ans, j'ai commencÃ© avec un simple Raspberry Pi 2 sur lequel Ã©tait installÃ© Docker Swarm. Au fil tu temps, j'ai migrÃ© vers deux
Raspberry Pi 3 d'abord avec Docker Swarm puis avec Kubernetes, puis ajoutÃ© un Raspberry Pi 4. Ensuite, il y a environ 2 ans, j'ai remplacÃ© ces Raspberry Pi par
deux Oranges Pi 5 Ã©quipÃ©s de disques NVME. Enfin, l'annÃ©e derniÃ¨re, j'ai intÃ©grÃ© un PC neuf Ã  mon cluster Kubernetes. Et cette annÃ©e, j'ai finalement dÃ©cidÃ© de
dÃ©brancher mes Oranges Pi pour ne converver que le PC.

## Le serveur

### Le matÃ©riel

Le serveur est un PC montÃ© moi-mÃªme pour l'occasion. Il possÃ¨de les caractÃ©ristiques suivantes :

- Processeur : AMD Ryzen 5 5800G
- RAM : 32 Go (2x 16Go DDR5 5200MHz CL40)
- Carte mÃ¨re: ASRock B650M-H/M.2+
- Alimentation: Cooler Master MWE Gold 550 FM (v2)
- Stockage: 1x SSD NVMe 512 Go
- Boitier: Fractal Design Core 1100

### Le systÃ¨me d'exploitation

Pour le choix du systÃ¨me d'exploitation, j'ai optÃ© pour un choix plutÃ´t exotique Ã  premiÃ¨re vue, mais assez intÃ©ressant : [NixOS](https://nixos.org/). NixOS est
une distribution Linux basÃ©e sur Nix, un gestionnaire de paquets fonctionnel. Cela implique que la configuration du systÃ¨me est dÃ©clarative et que les paquets
sont isolÃ©s les uns des autres. En plus de me simplifier l'installation et paquets de bases, NixOS me permet aussi de rapidement configurer kubernetes (k3s) et
d'autres services avec assez peu de configuration. CumulÃ© Ã  cela, j'ai activÃ© la fonctionnalitÃ© de [Flake](https://wiki.nixos.org/wiki/Flakes) qui m'ouvre la
voie Ã  encore plus de capacitÃ© Ã  la configuration.

### Le dÃ©ploiement du systÃ¨me

Avant d'utiliser NixOS, toutes mes infrastructures utilisaient toujours une distribution basÃ© sur Debian (Debian et Armbian plus prÃ©cisÃ©ment) et toute
l'installation des outils se faisaient par le biais de scripts Ansible.

Ansible et Nix Flake sont deux outils ayant un objectif similaire : permettre un dÃ©ploiement automatisÃ© et reproductible. Il faut tout de mÃªme noter que leur
procÃ©dÃ© de fonctionnement est assez diffÃ©rent. Ansible est un outils de dÃ©ploiement avec une configuration dite "impÃ©rative", c'est Ã  dire que l'on dÃ©crit les
Ã©tapes Ã  suivre pour arriver Ã  un Ã©tat donnÃ©. Nix Flake, quant Ã  lui, est un outil de dÃ©ploiement avec une configuration dite "dÃ©clarative", c'est Ã  dire que
l'on dÃ©crit l'Ã©tat final que l'on souhaite obtenir Ã  la fin.

Cette diffÃ©rence de paradigme est assez importante et c'est ce qui m'a poussÃ© Ã  essayer NixOS. En effet, il faut savoir que jusqu'Ã  prÃ©sent, je faisais tous mes
dÃ©ploiements via Ansible, mais au fur et Ã  mesure du temps, le coÃ»t de maintenance des scripts devenait de plus en plus important en raison des mises Ã  jours
des nombreuses dÃ©pendences nÃ©cessaires (k3s, networking, adressage des IPs, etc.). Avec Nix Flake, j'ai n'ai plus trop Ã  me soucier de cela, et mieux encore,
des morceaux de mes configurations sont plus facilement rÃ©utilisables. (C'Ã©tait dÃ©jÃ  un peu le cas avec Ansible, mais pas autant).

> [!TIP]
>
> Pour ceux qui souhaitent en savoir plus sur NixOS, je vous recommande de lire le [manuel officiel](https://nixos.org/manual/nixos/stable/).

Voici un petit exemple de configuration Nix pour installer et configurer K3S :

```nix
# Il faut imaginer que ce fichier est importÃ© ailleur dans la configuration, ce qui permet de
# fournir le champ `pkgs` et les autres variables.
{
  pkgs,
  kubeconfigFile,
  tokenFile,
  # Initialize HA cluster using an embedded etcd datastore.
  # If you are configuring an HA cluster with an embedded etcd,
  # the 1st server must have `clusterInit = true`
  # and other servers must connect to it using `serverAddr`.
  #
  # this can be a domain name or an IP address(such as kube-vip's virtual IP)
  masterHost,
  clusterInit ? false,
  kubeletExtraArgs ? [],
  nodeLabels ? [],
  nodeTaints ? [],
  disableFlannel ? true,
  nodeIps,
  ...
}: let
  lib = pkgs.lib;
in {
  # Installation de paquet systÃ¨mes
  environment.systemPackages = with pkgs; [
    k9s # k9s est un outil TUI pour kubernetes
    kubectl # CLI officiel pour kubernetes
    kubecolor # coloration syntaxique pour kubectl (facultatif)
    istioctl # outil de ligne de commande pour Istio
    kubernetes-helm # outil de gestion de paquets pour kubernetes
    clusterctl # CLI pour piloter kubernetes depuis son api
  ];

  # Configuration du pare-feu
  networking.firewall = {
    allowedTCPPorts = [
      6443 # k3s: required so that pods can reach the API server (running on port 6443 by default)
    ];
    allowedUDPPorts = [
      8472 # k3s, flannel: required if using multi-node for inter-node networking
    ];
  };

  # Configuration de k3s
  services.k3s = {
    enable = true;
    # On hÃ©rite des variables dÃ©finies plus haut
    inherit package tokenFile clusterInit;
    serverAddr =
      if clusterInit
      then ""
      else "https://${masterHost}:6443";

    # On spÃ©cifie le role du noeud
    role = "server";

    # On spÃ©cifie les flags Ã  passer Ã  k3s
    # https://docs.k3s.io/cli/server
    extraFlags = let
      flagList =
        [
          "--write-kubeconfig=${kubeconfigFile}"
          "--write-kubeconfig-mode=644"
          "--kube-apiserver-arg='--allow-privileged=true'" # required by kubevirt
          "--data-dir /var/lib/rancher/k3s"
          "--etcd-expose-metrics=true"
          # to enable dual-stack, these flags are required
          # https://docs.k3s.io/networking/basic-network-options#dual-stack-ipv4--ipv6-networking
          "--cluster-cidr=10.42.0.0/16,2001:cafe:42::/56"
          "--service-cidr=10.43.0.0/16,2001:cafe:43::/112"
          # disable some features we don't need
          "--disable-helm-controller" # we use fluxcd instead
          "--disable=traefik" # deploy our own ingress controller instead
          "--disable=servicelb" # we use metallb instead
          "--tls-san=${masterHost}"
          "--node-ip=${lib.concatStringsSep "," nodeIps}"
        ]
        ++ (map (label: "--node-label=${label}") nodeLabels)
        ++ (map (taint: "--node-taint=${taint}") nodeTaints)
        ++ (map (arg: "--kubelet-arg=${arg}") kubeletExtraArgs)
        ++ (lib.optionals disableFlannel ["--flannel-backend=none"])
        ++ (lib.optionals (!disableFlannel) ["--flannel-ipv6-masq=true"]);
    in
      lib.concatStringsSep " " flagList;
  };
}
```

Comme vous pouvez le constater, la configuration est assez lisible dans l'ensemble. Le language Nix permet d'effecter des opÃ©rations assez complexes et ce
script en est un exemple. En une cinquantaine de lignes, nous avons une configuration complÃ¨te pour installer et configurer k3s, configurer le pare-feu, et
installer quelques outils supplÃ©mentaires.

Si nous devions refaire la mÃªme chose avec Ansible, cela nous prendrait beaucoup plus de lignes (pas tant que Ã§a, mais tout de mÃªme) et surtout, cela nous
demanderait de rÃ©flÃ©chir en amont Ã  l'ordre d'exÃ©cution des tÃ¢ches Ã  effectuer, Ã  la gestion des erreurs, etc.

> [!CAUTION]
>
> Attention tout de mÃªme, NixOS n'est pas une solution miracle et il est possible de se retrouver dans des situations assez complexes si l'on ne fait pas
> attention. Il est donc important de bien comprendre les concepts de base avant de se lancer.
>
> Un autre point Ã  noter, c'est que NixOS, en plus de ne pas rÃ©specter les standards POSIX sur la structure du systÃ¨me de fichier (impliquant la mise en place
> de nombreux bricolages pour faire fonctionner certains programmes), demande une quantitÃ© de stockage plus importante que des distributions plus classiques.

## Pourquoi Kubernetes ?

Kubernetes est un orchestrateur de conteneurs open-source qui permet d'automatiser le dÃ©ploiement, la mise Ã  l'Ã©chelle et la gestion des applications
conteneurisÃ©es. Il est conÃ§u pour gÃ©rer des applications conteneurisÃ©es sur un cluster de machines. Il a Ã©tÃ© conÃ§u Ã  l'origine par Google et est maintenant
maintenu par la Cloud Native Computing Foundation.

Dans mon cas, Kubernetes me permet de dÃ©ployer et de faire la maintenance rapidement et facilement des applications sur mon serveur. Dans le cas oÃ¹ je dÃ©ploie
un grand nomrmes de services, avoir Kubernetes me simplifie grandement la gestion de tout cela.

NÃ©anmoins ! Qui dit simplicitÃ© au dÃ©ploiement, dit complexitÃ© Ã  la configuration de l'infrastructure. En effet, Kubernetes est un outil trÃ¨s puissant mais qui
peut Ãªtre difficile Ã  apprÃ©hender. Il est donc important de bien comprendre les concepts de base avant de se lancer.

## Processus de dÃ©ploiement

Jusque lÃ , j'ai surtout parlÃ© de NixOS et de Kubernetes sans Ãªtre exactement rentrÃ© dans les dÃ©tails
de *pourquoi* c'est effectivement plus simple Ã  utiliser. C'est ce que nous allons voir maintenant.

